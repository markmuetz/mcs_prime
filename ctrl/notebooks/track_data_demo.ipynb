{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c66afe6-33ae-4de5-a357-409347c7b534",
   "metadata": {},
   "source": [
    "# Demonstration of accessing data in V2 of global MCS database\n",
    "\n",
    "This notebook demonstrates how to access and perform simple analysis on V2 of the global MCS database. It gives example code of the basic methods of loading the data using `xarray`, for both the tracks data and the pixel-level data, as well as linking the two together. Some simple analysis is done.\n",
    "\n",
    "* Database as in Feng et al. (2021), but with full global analysis (i.e., not split into three regions).\n",
    "* Tracking as documented in the PyFLEXTRKR V2 document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2d8dd9-1381-477f-91c7-925ed314968d",
   "metadata": {},
   "source": [
    "## Acronyms\n",
    "\n",
    "* MCS: mesoscale convective system.\n",
    "* CCS: cold cloud system - the result of the PyFLEXTRKR algorithm. Often close to the 241K brightness temperature threshold but extended in the presence of precipitation.\n",
    "* PF: precipitation feature.\n",
    "\n",
    "## Accessing tracks data\n",
    "\n",
    "The MCS tracks are the result of applying the PyFLEXTRKR algorithm to the NASA Global Merged IR V1 infrared brightness temperature (Janowiak et al., 2017) and GPM IMERG V06B precipitation (Tan et al., 2019) datasets. The stored tracks are the *robust* MCS tracks: ones that have met the criteria set out in Feng et al. (2021), with lifetime-dependent thresholds on PF area, mean rainrate, rainrate skewness, and heavy rain ratio. The have also had both tropical cyclones and atmospheric rivers filtered out.\n",
    "\n",
    "### Tracks data files\n",
    "\n",
    "The MCS tracks dataset consist of NetCDF4 files. These are laid out as 1D, 2D and 3D arrays of data, with the main coordinate being `tracks`, and variable length data stored in a fixed length array (using a maximum duration of 400, equivalent to an MCS that last for 400 hr). A consequence of this is that all the data over the duration of the length of a given MCS will be NaNs or similar, and so the compression ratio of files on disk is very high. Hence, even though a file for a given year is only approximately 270MB on disk, its size in memory will be far larger. Fully loading one year using `xr.load_dataset` uses approximately 16G of memory. It is therefore sensible to use `xr.open_dataset` or `xr.open_mfdataset`, which access the dataset's metadata but do not load its data until they are needed.\n",
    "\n",
    "Note, the compression level of a field can be seen from `xarray.Dataset`: `dstracks.area.encoding`. The tracks dataset is compressed using compression level 4.\n",
    "\n",
    "### Using `xarray` to access data\n",
    "\n",
    "`xarray` is a convenient way of loading the NetCDF4 files in Python. Fields can generally be manipulated using `xarray` methods or by loading the values a `numpy` arrays and manipulating those. This notebook requires having the following Python packages correctly installed (using e.g. `conda`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53c6913a-367c-4140-881f-5b6cee13cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.geodesic\n",
    "import dask\n",
    "from IPython.display import clear_output\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# Use for .mp4 video:\n",
    "# plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "# Use for javascript animation:\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "import matplotlib.animation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "485431c4-fa4d-482e-9266-91be3343e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit these based on where these are on your system.\n",
    "statsdir = Path('/gws/nopw/j04/mcs_prime/mmuetz/data/MCS_Global/stats')\n",
    "pixeldir = Path('/gws/nopw/j04/mcs_prime/mmuetz/data/MCS_Global/mcstracking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa8e9c56-5f9a-4325-8759-00cad4008786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gws/nopw/j04/mcs_prime/mmuetz/data/MCS_Global/stats/mcs_tracks_final_extc_20000601.0000_20010101.0000.nc\n",
      "/gws/nopw/j04/mcs_prime/mmuetz/data/MCS_Global/stats/mcs_tracks_final_extc_20200101.0000_20210101.0000.nc\n"
     ]
    }
   ],
   "source": [
    "stats_paths = sorted(statsdir.glob('mcs_tracks_final_extc_????????.0000_????????.0000.nc'))\n",
    "print(stats_paths[0])\n",
    "print(stats_paths[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2564983a-b490-4396-b001-0637400dc6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A single year can be opened using:\n",
    "dstracks_2020 = xr.open_dataset(stats_paths[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77fb2a06-2048-40c2-82c2-e80f5aa34113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the full dataset - 2000/06 to 2021/12.\n",
    "# Note, this does not load the data - that will happen once `.load()` is called on a field or it is accessed.\n",
    "dstracks = xr.open_mfdataset(\n",
    "    stats_paths,\n",
    "    concat_dim=\"tracks\",\n",
    "    combine=\"nested\",\n",
    "    mask_and_scale=False,\n",
    ")\n",
    "# Each seperate file for each year defines its own index for tracks. Re-index with a global index.\n",
    "dstracks[\"tracks\"] = np.arange(0, dstracks.dims[\"tracks\"], 1, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffbeaca-e171-4a9c-b1e4-28341c0cb12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The times have a small offset from the exact times -- e.g. 34500 ns off. Correct this.\n",
    "def round_times_to_nearest_second(dstracks, fields):\n",
    "    def remove_time_incaccuracy(t):\n",
    "        # To make this an array operation, you have to use the ns version of datetime64, like so:\n",
    "        return (np.round(t.astype(int) / 1e9) * 1e9).astype(\"datetime64[ns]\")\n",
    "\n",
    "    for field in fields:\n",
    "        dstracks[field].load()\n",
    "        tmask = ~np.isnan(dstracks[field].values)\n",
    "        dstracks[field].values[tmask] = remove_time_incaccuracy(\n",
    "            dstracks[field].values[tmask]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fad2635-452d-4afe-a3dd-5b43202948be",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_times_to_nearest_second(dstracks_2020, ['base_time', 'start_basetime', 'end_basetime'])\n",
    "round_times_to_nearest_second(dstracks, ['base_time', 'start_basetime', 'end_basetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798e68c6-8eef-4a69-a6e7-6062fe4e6068",
   "metadata": {},
   "outputs": [],
   "source": [
    "dstracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962337ed-ddb2-4b91-8341-13a79c360a6f",
   "metadata": {},
   "source": [
    "`dstracks` is an `xarray.Dataset`. You can access its fields using e.g. `dstracks.base_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef8e63-b094-4b11-9867-d5a32891a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, times that start 1969 are equivalent to nans.\n",
    "dstracks.base_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57861e1-89a0-4304-976e-7c76967a059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values can be accessed as a `numpy` array:\n",
    "dstracks.area.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e14c2b-380b-42d8-94d6-7adabbecb050",
   "metadata": {},
   "source": [
    "The data values are laid out as follows. \n",
    "\n",
    "* Fields with only `tracks` as coords are single-valued for each track, e.g. `track_duration`.\n",
    "* Fields with coords `(tracks, times)` are lifetime variables for that track, where the first `track_duration` have actual values.\n",
    "  * E.g. `dstracks.areas`\n",
    "* Fields with coords `(tracks, times, mergers)` are lifetime variables, where each time can have up to 50 `mergers` associated with it.\n",
    "  * These are to do with the tracking of the clouds that merge/split into/from the MCS, e.g. `dstracks.merge_cloudnumber`\n",
    "* Fields with coords `(tracks, times, nmaxpf)` are lifetime variables, where each time can have up to 3 `nmaxpf` associated with it.\n",
    "  * These are properties of the up to 3 PFs associated with the cloud, e.g. `dstracks.pf_rainrate`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76b0a9c-d249-4711-adaa-027cb65038a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compression level info:\n",
    "dstracks.area.encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4c113a-a339-4eea-a2bf-9abb5bed6a4b",
   "metadata": {},
   "source": [
    "### Selecting tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b33da5-b9a8-4022-a6aa-f23262782fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A single track can be selected from its track number:\n",
    "track = dstracks.sel(tracks=234)\n",
    "track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc1d4d6-680c-4729-8a23-172d83e77dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might want to select tracks based on e.g. the time at which they are active:\n",
    "datetime = pd.Timestamp('2005-06-01 12:30').to_numpy()\n",
    "# `isel` selects on index. The expression on the RHS collapses the 2D field of `base_time` into a \n",
    "# 1D boolean field that is true if *any* base_time for a given track matches `datetime`.\n",
    "dstracks_at_time = dstracks.isel(\n",
    "     tracks=(dstracks.base_time.values == datetime).any(axis=1)\n",
    ")\n",
    "dstracks_at_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bab083-9d97-465f-bc47-2f1363ccead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or access tracks based on their location:\n",
    "# N.B. force a load of meanlat.\n",
    "dstracks.meanlat.load()\n",
    "# This suppresses a warning about chunk sizes.\n",
    "with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "    dstracks_tropical = dstracks.isel(\n",
    "        tracks=((dstracks.meanlat.values > -20) & (dstracks.meanlat.values < 20)).any(axis=1)\n",
    "    )\n",
    "dstracks_tropical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16173a60-aa12-4e38-a10c-8d12b9418d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each track can then be looped over using e.g.:\n",
    "for track_id in dstracks_at_time.tracks.values[:10]:  # Just get first 10.\n",
    "    track = dstracks_at_time.sel(tracks=track_id)\n",
    "    print(track.tracks.values.item(), track.track_duration.values.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1246bc-e7f6-4982-a8f4-f6b5012e4ed6",
   "metadata": {},
   "source": [
    "### Individual track properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488432a8-fb44-4548-a829-31bb21a6c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a track.\n",
    "track = dstracks.sel(tracks=234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6672134a-8d3d-48d9-bbae-a00179990790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access some of the track's properties:\n",
    "# Scalars can be accessed using:\n",
    "duration = track.track_duration.values.item()  # `.values.item()` unpacks the value into an int (in this case).\n",
    "print(f'track_duration: {duration}')\n",
    "# For times, it is useful to convert from a np.datetime64[ns] to a pandas Timestamp object or native datetime object:\n",
    "start_basetime = pd.Timestamp(track.start_basetime.values.item()).to_pydatetime()\n",
    "print(f'start_basetime: {start_basetime}')\n",
    "\n",
    "# Lifetime values can be accessed:\n",
    "# Note, e.g. area values are nan after the duration of the track:\n",
    "print(f'area (full): {track.area.values}')\n",
    "# Slice based on duration:\n",
    "print(f'area (sliced): {track.area.values[:duration]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a25776-2cfa-442e-9483-70ad0fe3d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mergers data are 2D fields (with -9999 indicating no values for merger number N):\n",
    "track.merge_cloudnumber.values[:duration, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55b1be7-9b62-4bc7-8de3-f06c21ae82fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly for PF data (with nan indicating no value):\n",
    "track.pf_rainrate.values[:duration, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ebe437-c083-4fba-a937-691fe90112a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple plot of the track's position can be made using:\n",
    "plt.scatter(track.meanlon.values[0], track.meanlat.values[0], marker='^')  # Start point.\n",
    "plt.scatter(track.meanlon.values[duration - 1], track.meanlat.values[duration - 1], marker='x')  # End point.\n",
    "plt.plot(track.meanlon.values, track.meanlat.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0d1c0-ac33-4c5b-b3ae-379d1c9058e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ccs_area_swath(ax, track, n_points=20):\n",
    "    \"\"\"Adds an area swath of the cold cloud system area, treating each CCS as a circle.\"\"\"\n",
    "    try:\n",
    "        # N.B. these are optional dependencies.\n",
    "        import shapely.geometry\n",
    "        import shapely.ops\n",
    "    except ImportError:\n",
    "        print('shapely not installed')\n",
    "        return\n",
    "    duration = track.track_duration.values.item()\n",
    "    time_indices = range(duration)\n",
    "    \n",
    "    # geoms will contain all the circles.\n",
    "    geoms = []\n",
    "    for i in time_indices:\n",
    "        lon = track.meanlon.values[i]\n",
    "        lat = track.meanlat.values[i]\n",
    "        radius = np.sqrt(track.ccs_area.values[i] / np.pi) * 1e3\n",
    "        circle_points = cartopy.geodesic.Geodesic().circle(\n",
    "            lon=lon, lat=lat, radius=radius, n_samples=n_points, endpoint=False\n",
    "        )\n",
    "        geom = shapely.geometry.Polygon(circle_points)\n",
    "        geoms.append(geom)\n",
    "    # Combine all the circles into a CCS swath.\n",
    "    full_geom = shapely.ops.unary_union(geoms)\n",
    "    ax.add_geometries(\n",
    "        (full_geom,),\n",
    "        crs=cartopy.crs.PlateCarree(),\n",
    "        facecolor=\"none\",\n",
    "        edgecolor=\"grey\",\n",
    "        linewidth=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261a9261-6f5c-4eef-8b97-6d08307cf016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nicer figure using cartopy projections and showing a circle based on the CCS area.\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "fig.set_size_inches((10, 5))\n",
    "ax.coastlines()\n",
    "ax.scatter(track.meanlon.values[0], track.meanlat.values[0], marker='^')\n",
    "ax.scatter(track.meanlon.values[duration - 1], track.meanlat.values[duration - 1], marker='x')\n",
    "ax.plot(track.meanlon.values, track.meanlat.values)\n",
    "add_ccs_area_swath(ax, track)\n",
    "ax.set_extent([110, 180, 0, 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6f6898-de5a-4b86-9e87-eb801df8e7a1",
   "metadata": {},
   "source": [
    "### Group properties of tracks\n",
    "\n",
    "Group properties for lots of tracks can be easily calculated by accessing the fields on an `xarray.Dataset` that contains many tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f62e981-795f-4618-93f6-feccdf72c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean track duration:\n",
    "dstracks.track_duration.values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7605ba-c24d-4184-b71e-a500829736d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing using xarray:\n",
    "dstracks.track_duration.mean().values.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa22447-f0fc-45e6-b702-f70583780a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tropical duration:\n",
    "dstracks_tropical.track_duration.values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184b7751-43b7-4329-9cd4-1dc1b90aa6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean area for each track:\n",
    "# `np.nanX` functions are useful for naturally dealing with the missing data.\n",
    "mean_areas = np.nanmean(dstracks.area.values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20112ec7-8b61-4332-b3fd-941dcb2955b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mean_areas, bins=np.linspace(0, 1e6, 101));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bede5d18-81df-44e1-a2f5-627a0b4b9858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing using xarray:\n",
    "xr_mean_areas = dstracks.area.mean(dim='times', skipna=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8742402-a97e-4410-a729-73f0cdf5bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(mean_areas == xr_mean_areas).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9655eef-acc8-4baa-a601-b7a07f40ac81",
   "metadata": {},
   "source": [
    "## Accessing pixel-level data\n",
    "\n",
    "Pixel-level data is stored separately from the MCS tracks data. These files contain the raw brightness temperature (tb) and precipitation fields, as well as a derived cloudnumber field, which is the area covered by the CCS and can be linked to a given track (see below).\n",
    "\n",
    "**NOTE** the values you get for this will depend on which files have been extracted from the \\*.tar archives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d76cb44-b0e4-4d8a-976d-8463ebe1cd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's useful to make a dict so that you can access each file by datetime:\n",
    "track_pixel_paths = sorted(pixeldir.glob(\"**/*.nc\"))\n",
    "date_path_map = {\n",
    "    dt.datetime.strptime(p.stem, \"mcstrack_%Y%m%d_%H%M\"): p\n",
    "    for p in track_pixel_paths\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b493128-6775-426c-91bb-1d0a865b0cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only 2019 fully uncompressed so far:\n",
    "list(date_path_map.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a29b75-7b15-4541-82b5-8be76b59c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(date_path_map.items())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c700636-a2ce-4a79-8d22-d3cbfaf0a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smaller datasets - load completely.\n",
    "dsframe = xr.load_dataset(track_pixel_paths[123])\n",
    "dsframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413203dd-5253-4bba-bc18-1917ab5f0db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_plot(dsframe, field, method='contourf', **kwargs):\n",
    "    time = pd.Timestamp(round(dsframe.time.values.item() / 1e9) * 1e9)\n",
    "    if 'cmap' not in kwargs and 'colors' not in kwargs:\n",
    "        kwargs['cmap'] = 'jet'\n",
    "    fig, ax = plt.subplots(subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    fig.set_size_inches((19, 5))\n",
    "    ax.set_title(time)\n",
    "    ax.coastlines()\n",
    "    im = getattr(ax, method)(dsframe.longitude, dsframe.latitude, dsframe[field].isel(time=0), **kwargs)\n",
    "    plt.colorbar(im)\n",
    "    return fig, ax\n",
    "\n",
    "cmap = mpl.cm.get_cmap('jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6099d1b3-a268-451f-ad5a-5581e17c5c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the TB data are not complete. For 2019-03-06 03:30 - See the missing values stretching from Russia/Japan to south of Australia.\n",
    "global_plot(dsframe, 'tb', levels=np.arange(200, 310, 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dfa0a1-1d46-41aa-aab7-89b5ee4655b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precipitation clearly more prevalent where TB low.\n",
    "global_plot(dsframe, 'precipitation', levels=[1, 2, 4, 8, 16, 32, 64], colors=[cmap(v) for v in np.linspace(0, 1, 7)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28bcf27-6761-49c4-94b1-4dceaccc7b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a derived field, which is based on the TB thresh. and uses PF data to extend these areas (Feng et al. 2021).\n",
    "global_plot(dsframe, 'cloudnumber');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9f9c03-0bf4-42fa-a177-a3097795a489",
   "metadata": {},
   "source": [
    "## Linking tracks to pixel-level data\n",
    "\n",
    "Every track contains a field with the values of the cloudnumber in the pixel-level data. This can be used to link each track to its pixel-level data, using the timestamp and the cloudnumber. The timestamp can be used to determine which pixel-level data file to load, and the cloudnumber references the equivalent field in the dataset (as shown in the figure above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a821228-7e74-4212-a288-387aaf70869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a tropical track from July 2019, that lasted more than 20 hours and less than 40.\n",
    "dates = pd.DatetimeIndex(dstracks_tropical.start_basetime.values)  # These containers make it easy to select on year, month...\n",
    "track = dstracks_tropical.isel(tracks=(\n",
    "    (dates.year == 2019) & \n",
    "    (dates.month == 7) & \n",
    "    (dstracks_tropical.track_duration > 20) & \n",
    "    (dstracks_tropical.track_duration < 40)\n",
    ")).isel(tracks=0)  # just select first track that meets criteria.\n",
    "duration = track.track_duration.values.item()\n",
    "# assert track.tracks.values.item() == 647749"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335815b1-42e2-4581-9a0c-b4db2874223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These can be used to work out which pixel-level data file to open.\n",
    "track_dates = [pd.Timestamp(d).to_pydatetime() for d in track.base_time.values[:duration]]\n",
    "track_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb238ce-4c69-4197-8908-1b0c61970c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These values reference the `cloudnumber` field within the pixel-level data.\n",
    "track.cloudnumber.values[:duration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe1b3b0-1a67-4916-a454-73201c825c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Prev line ensures figure not shown until animation.fig, ax = plt.subplots(subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "# Set up a figure to use for the animation below.\n",
    "\n",
    "margin_degree = 10\n",
    "minlon = track.meanlon.values[:duration].min()\n",
    "maxlon = track.meanlon.values[:duration].max()\n",
    "minlat = track.meanlat.values[:duration].min()\n",
    "maxlat = track.meanlat.values[:duration].max()\n",
    "aspect = (maxlon - minlon + 2 * margin_degree) / (maxlat - minlat + 2 * margin_degree)\n",
    "fig.set_size_inches((18, 18 / aspect))\n",
    "fig.subplots_adjust(left=0.05, right=0.95, bottom=0.05, top=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f51fb0-2d42-4445-9610-782e5e797eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an animation of the track, CCS, TB, and precip.\n",
    "def plot_track_link_pixel(i):\n",
    "    print(f'{i + 1}/{duration}')\n",
    "    ax.clear()\n",
    "    ax.set_extent((minlon - margin_degree, maxlon + margin_degree, minlat - margin_degree, maxlat + margin_degree))\n",
    "    ax.coastlines()  \n",
    "\n",
    "    date = track_dates[i]\n",
    "    ax.set_title(date)\n",
    "    # Get the cloudnumber to link to the pixel data.\n",
    "    cn = track.cloudnumber.values[:duration][i]\n",
    "    # Get the correct pixel-level dataset frame for the current time of the track.\n",
    "    dsframe = xr.load_dataset(date_path_map[date])\n",
    "    # Display pixel data.\n",
    "    ax.contourf(dsframe.lon, dsframe.lat, dsframe.isel(time=0).precipitation, levels=[1, 2, 4, 8, 16, 32, 64], colors=[cmap(v) for v in np.linspace(0, 1, 7)])\n",
    "    ax.contour(dsframe.lon, dsframe.lat, dsframe.isel(time=0).tb, levels=[241], colors=['grey'])\n",
    "    # Here, only the values within the frame with the correct cloudnumber are True (==1).¶\n",
    "    ax.contour(dsframe.lon, dsframe.lat, dsframe.isel(time=0).cloudnumber == cn, levels=[0.5], colors=['r'])\n",
    "    # Display track path.\n",
    "    ax.scatter(track.meanlon.values[0], track.meanlat.values[0], marker='^', c='r')\n",
    "    ax.scatter(track.meanlon.values[duration - 1], track.meanlat.values[duration - 1], marker='x', c='r')\n",
    "    ax.scatter(track.meanlon.values[i], track.meanlat.values[i], marker='o', c='r')\n",
    "    ax.plot(track.meanlon.values, track.meanlat.values, 'r-')\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "anim = matplotlib.animation.FuncAnimation(fig, plot_track_link_pixel, frames=duration, interval=500)\n",
    "anim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537ec2bd-624f-40ce-ad00-e95b75cf1273",
   "metadata": {},
   "source": [
    "* Track: red line with circle showing its centroid.\n",
    "* CCS: red outline.\n",
    "* TB: grey contour at 241K (N.B. often coincides with CCS).\n",
    "* precipitation: filled contours.\n",
    "* This MCS track starts in Venezuela and travels west into Colombia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa62b7b-a594-415d-a0e2-bcd287823ab2",
   "metadata": {},
   "source": [
    "### Merge/Split clouds from an MCS\n",
    "\n",
    "There is more data in the track that links to the pixel-level data. In particular, the `merge_cloudnumber` and `split_cloudnumber` fields reference clouds that merge into, or split from, the tracked MCS. Remembering that the initial algorithm tracks **all** clouds above a certain size, and whether or not a particular track constitutes an MCS is only determined after the main tracking has taken place, this means that there is extra information about how an MCS grows and decays from these fields. A cloudnumber can be in both `merge_cloudnumber` and `split_cloudnumber`, meaning it has split from an MCS, but will merge back into it in due course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a66aae3-08be-4078-aa49-779fa2a89fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "margin_degree = 5\n",
    "aspect = (maxlon - minlon + 2 * margin_degree) / (maxlat - minlat + 2 * margin_degree)\n",
    "fig.set_size_inches((18, 18 / aspect))\n",
    "fig.subplots_adjust(left=0.05, right=0.95, bottom=0.05, top=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525210d3-c78a-40aa-af51-3c242e74f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cloud_merge_split(i):\n",
    "    print(f'{i + 1}/{duration}')\n",
    "\n",
    "    cn = track.cloudnumber[i]\n",
    "    ax.clear()\n",
    "    ax.set_extent((minlon - margin_degree, maxlon + margin_degree, minlat - margin_degree, maxlat + margin_degree))\n",
    "    ax.coastlines()  \n",
    "    date = track_dates[i]\n",
    "\n",
    "    dsframe = xr.open_dataset(date_path_map[date])\n",
    "    dsframe.cloudnumber.load()\n",
    "\n",
    "    ax.contour(dsframe.lon, dsframe.lat, dsframe.cloudnumber[0] == cn, levels=[0.5], colors=['k'])\n",
    "    \n",
    "    # Use Python sets so that it is easy to work out e.g. intersections.\n",
    "    mcn = set(v for v in track.merge_cloudnumber.values[i] if ~np.isnan(v) and v != -9999)\n",
    "    scn = set(v for v in track.split_cloudnumber.values[i] if ~np.isnan(v) and v != -9999)\n",
    "    for cn in mcn & scn:\n",
    "        # In both.\n",
    "        ax.contour(dsframe.lon, dsframe.lat, dsframe.cloudnumber[0] == cn, levels=[0.5], colors=['purple'])\n",
    "    for cn in mcn - scn:\n",
    "        # Only in merge_cloudnumber.\n",
    "        ax.contour(dsframe.lon, dsframe.lat, dsframe.cloudnumber[0] == cn, levels=[0.5], colors=['g'])\n",
    "    for cn in scn - mcn:\n",
    "        # Only in split_cloudnumber.\n",
    "        ax.contour(dsframe.lon, dsframe.lat, dsframe.cloudnumber[0] == cn, levels=[0.5], colors=['r'])\n",
    "    ax.scatter(track.meanlon.values[0], track.meanlat.values[0], marker='^', c='r')\n",
    "    ax.scatter(track.meanlon.values[duration - 1], track.meanlat.values[duration - 1], marker='x', c='r')\n",
    "    ax.scatter(track.meanlon.values[i], track.meanlat.values[i], marker='o', c='r')\n",
    "    ax.plot(track.meanlon.values, track.meanlat.values, 'r-')\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "anim = matplotlib.animation.FuncAnimation(fig, plot_cloud_merge_split, frames=duration, interval=500)\n",
    "anim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9724656a-52a4-48ab-b65e-a3ba81ac0be0",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Red line: path of MCS with circle showing its centroid\n",
    "* Black: MCS CCS\n",
    "* Green: clouds that will merge into MCS\n",
    "* Red: clouds that have split from MCS\n",
    "* Purple: clouds that have split from MCS and will merge back into it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d445f8-4e17-43b3-85eb-6911ba0cd56f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MCSs that start/end with splits/merges\n",
    "\n",
    "It is possible for an MCS track to begin as the splitting of two clouds, or end with merging into another cloud. In these cases, this information is recorded in the track.\n",
    "\n",
    "* Splits: if `track.start_split_cloudnumber` > 0, then the MCS track began as the split of a larger cloud. In some cases, the progenitor cloud could have been an MCS.\n",
    "* Merges: if `track.end_merge_cloudnumber` > 0, then the MCS track ended as the merge of two clouds. In some cases, the merged cloud could be an MCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df037a28-4420-452a-bcb6-8131843baab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dstracks_2020.start_split_cloudnumber.load()\n",
    "dstracks_2020.end_merge_cloudnumber.load()\n",
    "\n",
    "ntracks = len(dstracks_2020.tracks)\n",
    "nsplits = (dstracks_2020.start_split_cloudnumber.values > 0).sum()\n",
    "nmerges = (dstracks_2020.end_merge_cloudnumber.values > 0).sum()\n",
    "\n",
    "print(f'nsplits={nsplits} - {nsplits / ntracks * 100:.1f}%')\n",
    "print(f'nmerges={nmerges} - {nmerges / ntracks * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05388736-a67e-4818-bcd3-2269d177ccbf",
   "metadata": {},
   "source": [
    "So about 1/3 MCS tracks start or end in a split/merge. These are splits/merges from clouds, not necessarily from other MCSs.\n",
    "\n",
    "Finding if it split/merged from an MCS is a little more involved.\n",
    "\n",
    "* Split: examine all `dstracks.cloudnumber` at t - 1hr, and see if they match the value of `track.start_split_cloudnumber`.\n",
    "* Merge: examine all `dstracks.cloudnumber` at t + 1hr, and see if they match the value of `track.end_merge_cloudnumber`.\n",
    "\n",
    "Code for these is shown next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c69ccd-0b13-4785-b5ae-8ed831161e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N.B. This is very slow if done on the full dstracks dataset. Do for one year only.\n",
    "dstracks_2020.start_split_cloudnumber.load()\n",
    "dstracks_2020.end_merge_cloudnumber.load()\n",
    "\n",
    "ntracks = 1000\n",
    "nsplits = 0\n",
    "nmerges = 0\n",
    "for trackid in dstracks_2020.tracks.values[:ntracks]:\n",
    "    if trackid % 100 == 0:\n",
    "        print(f'{trackid / ntracks * 100:.1f}%')\n",
    "        clear_output(wait=True)\n",
    "    track = dstracks_2020.sel(tracks=trackid)\n",
    "\n",
    "    sscn = track.start_split_cloudnumber.values.item()\n",
    "    emcn = track.end_merge_cloudnumber.values.item()\n",
    "\n",
    "    if sscn > 0:\n",
    "        mask = ((dstracks_2020.cloudnumber == sscn) & \n",
    "                (dstracks_2020.base_time == track.base_time.values[0] - int(3600e9))).any(axis=1)\n",
    "        nprev_tracks = mask.sum()\n",
    "        if nprev_tracks == 1:\n",
    "            nsplits += 1\n",
    "            prev_track = dstracks_2020.isel(tracks=mask).isel(tracks=0)\n",
    "        elif nprev_tracks > 1:\n",
    "            raise Exception('more than one progenitor cloud found')\n",
    "    if emcn > 0:\n",
    "        mask = ((dstracks_2020.cloudnumber == emcn) & \n",
    "                (dstracks_2020.base_time == track.base_time.values[0] + int(3600e9))).any(axis=1)\n",
    "        nnext_tracks = mask.sum()\n",
    "        if nnext_tracks == 1:\n",
    "            nmerges += 1\n",
    "            next_track = dstracks_2020.isel(tracks=mask).isel(tracks=0)\n",
    "        elif nnext_tracks > 1:\n",
    "            raise Exception('more than one merged cloud found')\n",
    "            \n",
    "clear_output(wait=True)\n",
    "print(f'MCS nsplits={nsplits} - {nsplits / ntracks * 100:.1f}%')\n",
    "print(f'MCS nmerges={nmerges} - {nmerges / ntracks * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90bc515-b9f0-4163-b8cb-dba78e6826c8",
   "metadata": {},
   "source": [
    "From this small sample, about 30% of clouds start as splits from an existing MCS, and about 20% end as merges into another MCS.Retrieved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9500769-7da8-4755-90e3-6a9e6bd71739",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how to access V2 MCS data using Python and `xarray`, including:\n",
    "\n",
    "* Accessing the tracks data, including subsetting, track properties, and group properties of tracks.\n",
    "* Accessing pixel-level data.\n",
    "* Linking tracks to pixel-level data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb1754d-c97e-44ae-ada5-fe9150e41dd4",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* Feng, Zhe, L Ruby Leung, et al. (2021). “A global high-resolution mesoscale convective system database using satellite-derived cloud tops, surface precipitation, and tracking”. In: Journal of Geophysical Research: Atmospheres 126.8, e2020JD034202. https://doi.org/10.1029/2020JD034202\n",
    "* Janowiak, J., Joyce, B., & Xie, P. (2017). NCEP/CPC L3 half hourly 4km global (60S - 60N) merged IR V1. Retrieved from https://doi.org/10.5067/P4HZB9N27EKU\n",
    "* Tan, J., Huffman, G. J., Bolvin, D. T., & Nelkin, E. J. (2019). Diurnal cycle of IMERG V06 precipitation. Geophysical Research Letters, 46(22), 13584–13592. https://doi.org/10.1029/2019GL085395\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcs_prime_env",
   "language": "python",
   "name": "mcs_prime_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
